# Consumption: where to read data from

## Published paths

**Consumers (dashboard, export scripts, reports) should read from:**

| Path | Content |
|------|--------|
| `data/processed/` | All build outputs: match scores (00), team stats (01), match summary (02), player stats (03–11), substitution impact (12), momentum (13), managers (14), team tactical profiles (15), age curves (16). Parquet files. |
| `data/derived/` | `player_appearances.parquet`, `player_incidents.parquet`, `match_scores.parquet`; optionally `player_appearances.csv`. |
| `data/index/matches.csv` | Central match index (match_id, season, competition_slug, round, match_date, etc.). |
| `data/index/players.csv` | Unique players (id, name, slug, appearance count). |

These paths are the **stable contract**. Paths are configurable via `config/env.yaml` or env vars (see `docs/setup.md`); by default they live under the project root.

## Latest successful run

- **`data/index/last_successful_run.txt`** — Contains a single line: the ISO timestamp (UTC) of the last successful pipeline run. Written by `scripts/run_scheduled_pipeline.sh`. Use it to check freshness (e.g. alert if older than 24 hours).
- **`data/index/latest_successful_run.json`** (optional) — If generated by your run script, can contain e.g. `{"ended_utc": "2025-02-21T06:00:00Z", "steps_run": "index,derived,...,validate"}` for programmatic checks.

## Freshness

The DQ step can optionally check that key artifacts are not older than N hours (see `scripts/build/dq_check.py`). If enabled, a failed freshness check will appear in the DQ report so you know data may be stale.

## Versioning / snapshots

There is no built-in versioning. For point-in-time reads, use your own snapshot copy (e.g. `data/snapshots/<timestamp>/`) as described in `docs/retention.md`.
